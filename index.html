<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  
    
      
    

    
  

  

  
    
      
    

    
  

  
    
      
    

    
  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Monda:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Lobster Two:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.3">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.3" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="无病呻吟...">
<meta property="og:type" content="website">
<meta property="og:title" content="少年游">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="少年游">
<meta property="og:description" content="无病呻吟...">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="少年游">
<meta name="twitter:description" content="无病呻吟...">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.3',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title>少年游</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">少年游</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-主页"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-标签"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-分类"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-文章"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/12/20/GoogLeNet模型学习/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Li">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="http://oyvr3xxmh.bkt.clouddn.com/17-11-4/36375047.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="少年游">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/12/20/GoogLeNet模型学习/" itemprop="url">GoogLeNet模型学习</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-12-20T16:53:38+08:00">
                2017-12-20
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/note/" itemprop="url" rel="index">
                    <span itemprop="name">note</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="GoogLeNet-Inception-Net"><a href="#GoogLeNet-Inception-Net" class="headerlink" title="GoogLeNet(Inception Net)"></a>GoogLeNet(Inception Net)</h3><p>&emsp;&emsp;GoogLeNet是2014年ImageNet Classification的冠军得主，该架构的主要特点是充分地利用了网络内部的计算资源，并在设计上精雕细琢是的最终的层数达到了22层。其架构的决定基于Hebbian理论（维基的解释：我们可以假定，反射活动的持续与重复会导致神经元稳定性的持久性提升……当神经元A的轴突与神经元B很近并参与了对B的重复持续的兴奋时，这两个神经元或其中一个便会发生某些生长过程或代谢变化，致使A作为能使B兴奋的细胞之一，它的效能增强了）。</p>
<p>&emsp;&emsp;2014年是卷积神经网络的绽放年，对比之前介绍过的同一年出现的VGG网络，GoogLeNet的一个非常大的优势便是其要训练的参数远小于VGG网络，故计算成本要低很多。论文中还说到其论文名字中的deep有着两层的含义，其一是引入了了一种新的层次组织方式(Inception module)；其二是更直观地便是加深了网络的深度。</p>
<h4 id="1-相关工作"><a href="#1-相关工作" class="headerlink" title="1 相关工作"></a>1 相关工作</h4><p>&emsp;&emsp;在这里主要对1x1卷积层进行介绍，原文中描述了在1x1卷积层后跟上ReLU层，使当前的网络能轻易地集成该卷积层。所以在该网络中大量地采用了1x1的卷积核，其主要目的是对数据进行了降维，从而移除计算的瓶颈。这样做不仅能增加网络的深度而且在保证网络的宽度的同时对最终的性能没有明显的损失。</p>
<p>&emsp;&emsp;先说说降维，因为3x3和5x5的卷积核在filter数目大的时候对前一层网络进行卷机操作时相当的耗时，所以通过在两者之间加入1x1卷积核将维度降下来。比如一张100x100且channels为100的图片经过20个filter的1x1卷积层后维度就降到了100x100x20。当然既然能降维，该卷积层同样能做到升维，所以其中一个重要的作用便是调节维度；另一个好处便是1x1卷积层后面直接可以加入ReLU非线性层，增加模型的复杂度（这个在VGG的网络中也采用过）。</p>
<p>&emsp;&emsp;论文中还提到了R-CNN将物体检测分为了两个步骤，首先是利用颜色和纹理等低级信号，以先不管类别的方式去产生目标位置的候选区域；然后利用CNN分类器去上述的区域中识别对象。</p>
<h4 id="2-动机和高层次的思考"><a href="#2-动机和高层次的思考" class="headerlink" title="2 动机和高层次的思考"></a>2 动机和高层次的思考</h4><p>&emsp;&emsp;GoogLeNet同样也提出了想直截了当地增加最后神经网络的性能的一个方法便是增加网络的深度（该观点在VGG也同样地提出过），但深度的增加也存在着两个弊端：</p>
<ul>
<li>其一，更深的网络意味着更多的参数，这样会导致网络更容易地出现过拟合的现象，尤其是当训练的带标记的数据有限。这将会导致网络出现瓶颈，因为高质量的带标记的训练数据的获得是非常棘手和昂贵的；</li>
<li>其二，一味地增加深度同样会极大地增加计算资源。比如在一个较深的神经网络中，如果有两层卷积层是相互连接的，那么它们之中filters数目的增加将会导致计算量的平方式的增加。而且当增加的能力使用率很低时（比如大多数的权重在最后都会趋于0），那么很大的计算资源就被浪费了。</li>
</ul>
<p>&emsp;&emsp;而如何处理这两个弊端呢？一个比较好的方法便是将全连接层甚至是卷积层以稀疏连接层代替，这个想法来自Arora等的工作，他们的主要成果表明了如果以一个大型的稀疏神经网络来表示数据集的概率分布，那么通过分析上一层激活后的相关统计信息并聚集输出高度相关的神经元，便可以一层一层地构建最优的网络拓扑结构。</p>
<p>&emsp;&emsp;因为计算机对非均匀的稀疏数据的计算性能很差，早先的网络采用了随机的系数连接来打破网络的对称性提高学习的速率，因此在AlexNet中又重新地采用了全连接层来达到更好地并行计算能力。所以现在的主要问题便是是否存在这样的一个中间步骤，既能够充分地利用网络的稀疏结构，也能够使计算机对密集矩阵的高计算性能得到使用。大量的文表明了在稀疏矩阵的计算上可以通过将它们聚类为一个相对于密集的子矩阵从而使现有的技术的实际性能运用到矩阵运算中，Inception便是基于此提出了Inception module。</p>
<h4 id="3-架构细节"><a href="#3-架构细节" class="headerlink" title="3 架构细节"></a>3 架构细节</h4><p>&emsp;&emsp;Inception架构的主要思想便是如何在卷积网络中找出一个近似的局部最优的稀疏结构，且该结构能被密集组件覆盖，得到这么一个结构后便能将其在空间中不断地重复最后构建整个网络。因此根据Arora等人提出的层次结构，将filter组成一个filter bank构成一层。目前Inception的架构的filter的尺寸被限制为1x1，3x3和5x5的，这个是基于便利性考虑的。同样因为池化层操作在目前大多数网络中都有着不错的效果，所以在该结构中同样增加一条并行的池化线，作者首先提出了如下的结构：</p>
<p><img src="http://oyvr3xxmh.bkt.clouddn.com/17-12-20/7901825.jpg"><br>&emsp;&emsp;如上的Inception模块在前一层之后跟着三个不同大小的卷积核以及一个max pooling核。采用了不同大小的卷积核意味着能得到不同的感受野，而针对每种卷积核最后只需要分别设置不同的pad便能得到相同维度的特征并进行拼接。而随着网络的深度加深，所需要捕获更高层次的抽象信息，那么就要使3x3和5x5卷积核的比例在深网络中加大。</p>
<p>&emsp;&emsp;但该组件的一个很大的问题便是，即使是5x5卷积核的数量不都，当filters数目很大时其参数的代价是过于昂贵的（比如上一层的输出是100x100x64，那这一层的输出是100x100x128，那么光一个5x5的卷积核所需要的参数便是64x5x5x128）。这个问题在加入了池化组件后会变得更加的明显，因为输出的filter的数量是等同于上一阶段filter的数量(即卷积核的数量)，而池化层和卷积层的合并势必会导致这一阶段到下一阶段输出的增加（因为在加入池化层后缩小了数据的长宽的维度，必定会增加其高度的维度，而卷积层的filter数目必须得和池化的filter数目保持一致）。所以尽管这种结构可能会覆盖最优的稀疏结构，但是随着阶段的增加其计算量过于庞大。</p>
<p>&emsp;&emsp;为了解决上面描述的问题，论文中说到需要先进行信号和信息的压缩对数据进行降维处理，然后再传入3x3和5x5的卷积核，所以在这里使用了1x1的卷积核对数据先进行降维处理，具体结构如下所示：</p>
<p><img src="http://oyvr3xxmh.bkt.clouddn.com/17-12-20/98447924.jpg"><br>&emsp;&emsp;从上图可以看到上一层的输出先经过1x1的卷积核进行处理再传入大的卷积核中，比如上一层的输出为100x100x64，如果先经过32个1x1的卷积核处理再传入128个5x5x32的卷积核中最后同样输出的也是100x100x128的数据，但是其参数的总量大约减少了四倍。该结构还有一个好处便是，它能是下一阶段的卷积层以不同的感受野去提取到上一阶段的特征并将它们整合在一起。</p>
<h4 id="4-GooLeNet"><a href="#4-GooLeNet" class="headerlink" title="4 GooLeNet"></a>4 GooLeNet</h4><p><img src="http://oyvr3xxmh.bkt.clouddn.com/17-12-20/29711383.jpg"><br>&emsp;&emsp;上表展示了在当时比赛中提交的最成功的一个例子，下面将详细分析下上表。在该网络中的所有卷积层、池化层后均采用的是ReLU作为激活函数，该网络的输入感受野是224x224x3,3为RGB的三条通道，输入数据也只经过平均化的处理（即使RGB数值以0为中心，位于-1到1之间）。</p>
<p>&emsp;&emsp;“#3x3 reduce”和“#5x5 reduce”代表了降维所用的1x1的卷积核的个数。比如看表的第五行（inception（3a）），上一层的输出是28x28x192，Inception module中直接经过1x1的卷积核后输出的channels是64，经过3x3的卷积核时先用1x1卷积核把192维降到了96维然后经过3x3卷积核输出的channels是128,5x5的卷积核是先降维到32，然后输出的channels是32，pooling直接输出的channels是32，这样全部合并后是256维，所以通过这个inception module后输出的数据size是28x28x256。</p>
<p>&emsp;&emsp;GoogLeNet架构中还有几个需要注意的点是：</p>
<ul>
<li>在最后的输出层之前采用Average Pooling代替全连接层,该做法使性能提升了0.6%；</li>
<li>还是在Average Pooling后增加了一个全连接层只为了以后进行微调；</li>
<li>尽管将全连接层移除，但dropout仍旧还是被使用，dropout值为0.7；</li>
<li>因为层数比较深为了防止发生梯度消失，增加了两个辅助分类器来进行反向传播，可以从下图中看到该结构中总共有三个softmax，这两个辅助分类器分别位于Inception（4a）和Inception（4d）后面，在实际测试的时候这两个分类器将不使用。<br><strong>下面为完整的GoogLeNet架构图：</strong></li>
</ul>
<p><img src="http://oyvr3xxmh.bkt.clouddn.com/17-12-20/31510768.jpg"><br>&emsp;&emsp;该模型在训练的过程采用了异步的随机梯度下降算法，并设置了0.9的momentum值，针对学习率设置采用的是每经过8个epochs学习速率减小4%。此外还用到了诸如Polyak平均、光度失真、随机插值等方法。</p>
<p>&emsp;&emsp;在进行测试的过程中，论文采取了如下几种方法：</p>
<ol>
<li>独立地训练了7个版本的模型，这七个模型初始化的权重和学习率均相同，唯一的区别便是下采样采取的方法和它们从输入中获得的感受野的随机性不同;</li>
<li>针对测试集，采取了一些和AlexNet中提到的方法类似的方法，首先将原始测试图片的宽或高分别resize成256,288,320,352四种，并对这些长方形图片分别从左、中、右裁剪出三个正方形（肖像图是上中下）。然后对这些裁剪的图分别取左上、左下、右上、右下、中心以及整张图片，将上述六种图片均resize成224x224，最后将上述处理完后的图片再做一次镜像翻转，然后作为测试集输入。经过这样的处理，一张图片便可以得到4x3x6x2=144张裁剪图，最后softmax输出的结果是平均这些图片得到的结果。</li>
</ol>
<h4 id="5-总结"><a href="#5-总结" class="headerlink" title="5 总结"></a>5 总结</h4><p>&emsp;&emsp;GoogLeNet网络的重点如下：</p>
<ol>
<li>Inception module的提出，使网络结构既保证稀疏性，又利用了密集矩阵的高计算性能;</li>
<li>1x1卷积核的使用，在该网络中1x1卷积核的使用，降低了特征的维度，最后极大地减少了参数数量和运算量；</li>
<li>后的分类器部分只采用了一个average pooling层和一个全连接层（其实全连接层也可以去掉），也在一定程度上降低了运算的数量。</li>
</ol>
<h4 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h4><p><a href="https://arxiv.org/abs/1409.4842" target="_blank" rel="external">GoogLeNet</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/12/18/VGG模型学习/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Li">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="http://oyvr3xxmh.bkt.clouddn.com/17-11-4/36375047.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="少年游">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/12/18/VGG模型学习/" itemprop="url">卷积神经网络模型学习（二）</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-12-18T15:30:19+08:00">
                2017-12-18
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/note/" itemprop="url" rel="index">
                    <span itemprop="name">note</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="VGG"><a href="#VGG" class="headerlink" title="VGG"></a>VGG</h3><p>&emsp;&emsp;VGG网络由牛津大学提出，并发表于2015年的ICLR会议上，该论文针对每一个卷积层采用了一个3x3的卷积核对图像做卷积，并基于当时技术的配置将卷积神经网络的层数推向了16-19层。VGG网络在2014年的ImageNet比赛中获得了物体检测的冠军以及图像分类的亚军。</p>
<h4 id="1-ConvNet配置"><a href="#1-ConvNet配置" class="headerlink" title="1 ConvNet配置"></a>1 ConvNet配置</h4><h5 id="1-1-架构"><a href="#1-1-架构" class="headerlink" title="1.1 架构"></a>1.1 架构</h5><p>&emsp;&emsp;VGG-16网络唯一所做的预处理便是将输入的224x224图片的每个像素减去RGB的均值（这个操作是使得输入的各个维度的数据都能中心化到0，还可以针对每个数据除以rgb最大值255使所有输入数据均处于-1-1之间）。在该网络中使用了3x3的卷积核（感受野为3x3），这是一个和之前LeNet5以及AlexNext相比非常小的卷积核，同时在该网络中还用到过1x1的卷积核（这个可以看做是对输入通道的线性变化）。卷积核的stride设置为1，padding的设置为same，池化操作为2x2的窗口，步长为2。最后的全连接层分别为4096、4096、1000通道，这和之前的网络相比没什么区别，此外采用的激活函数也仍旧是ReLU。VGG-16网络还有一个操作是它不再使用AlexNet中提到过的LRN，因为它觉得这个方法对准确率的提升不明显反而增加了内存的消耗和计算的时间，下面是简化版的VGG-16架构：</p>
<p><img src="http://oyvr3xxmh.bkt.clouddn.com/17-12-18/16448630.jpg"></p>
<h5 id="1-2-配置"><a href="#1-2-配置" class="headerlink" title="1.2 配置"></a>1.2 配置</h5><p>&emsp;&emsp;在该论文中，该卷积网络的配置如下表所示：</p>
<p><img src="http://oyvr3xxmh.bkt.clouddn.com/17-12-17/67520009.jpg"><br>&emsp;&emsp;从上表中可以看到总共有六个网络（A-E），它们之间除了层数的不同以外，其它的诸如stride等参数全部一致。每一层的channels也是相对较小的，从第一层的64每次增加一倍到最后达到512，下表展示了这些网络的参数个数总数，可以看出尽管层数增加了很多，但总的参数的数量并没有增加很多。</p>
<p><img src="http://oyvr3xxmh.bkt.clouddn.com/17-12-17/39393803.jpg"><br>&emsp;&emsp;可以容易地看到2个3x3的卷积核的感受野大小和一个5x5的卷积核感受野大小相似，3个3x3的卷积核的感受野同一个7x7的卷积核的感受野相似。那么相比于一个7x7的卷积核，3个3x3的卷积核堆叠有什么好处？其一：3个3x3的卷积核对应三层卷积层，能比一层卷积层多出两个非线性层处理，使得最终的模型更加复杂，辨别力更强；其二：参数数量缩减，以前一个7x7的卷积核（假设有C的通道数），那么参数的数量是49C^2，而现在的参数是3（3^2 C^2 ）=27C^2。在表1中的1x1卷积核的本质上是将输入进行线性投影后加入一个非线性层。</p>
<h4 id="2-训练和测试"><a href="#2-训练和测试" class="headerlink" title="2 训练和测试"></a>2 训练和测试</h4><p>&emsp;&emsp;训练的过程基本和AlexNet的训练过程类似，使用了随机梯度下降（基于反向传播）并将momentum值设置为0.9，mini batch的值为256，dropout参数设置为0.5，权值衰减的措施也如AlexNet一样，初始值为0.01每当validation数据集的准确率基本不变的时候减小十倍。最终该模型迭代了370000次（74epochs），尽管参数的数量和网络的层数都要大于AlexNet但最终只需要更少的epochs，推测原因应该是：1.更大的层数和更小的卷积核导致的隐式正则化；2.对每层的参数初始化采取了正确的方法。<br>&emsp;&emsp;VGG网络的权重参数初始化是首先使用表1中的A网络，用随机的参数训练该网络至收敛，然后将训练完成的参数去初始化剩下B-E网络的前四层卷积层和最后的三层全连接层，其余层仍旧使用随机参数。<br>&emsp;&emsp;在该篇论文中用了很多篇幅去强调了网络输入图片的尺寸问题，对于训练的图片采取把图片全部转换成边长为S的正方形（如S=256便是AlexNet所采用的尺寸，还有S=384等），然后对转化好的图片随机裁剪224x224的部分去训练。该模型采取了两种方法去设置S，</p>
<ol>
<li>单尺度训练：先把所有图片设置为256x256然后裁剪后进行训练得到训练好的模型，接着再把所有图片设置为384x284，用S=256时得到的参数去初始化S=384时候的参数，并把学习速率调低十倍；</li>
<li>多尺度训练：所有图片的尺寸并不是唯一的，即它们是随机于〖[S〗_min,S_max]（S_min=256，S_max=512），这样的话就会使每张图片的尺寸不尽相同，然后仍然是对图片进行裁剪将裁剪后224x224的图片作为训练集进行训练，（原文说因为图片中物体的大小有不同的size，所以这样做能把这点考虑进去，而且是通过尺寸的抖动增大了数据集），同样这里采取了S=384训练好后的模型参数来进行初始化，并设置学习速率为0.001。</li>
</ol>
<p><strong>网络的测试过程中，针对测试图片的scale处理也采取了两种方法：</strong></p>
<ol>
<li>dense evaluation：即全连接卷积网络，针对的是整张训练图片。在这里同样采取了图片的水平翻转增加了测试集，最后的结果由原始图片和翻转图片的结果取平均</li>
<li>multi-crop evaluation：即针对测试图片进行多重的裁剪，这样会使计算量变得非常大，因为模型要针对每一个crop进行计算。论文中还提到了这两种方法之间可以进行互补，原因呢？两种方法有着不同的卷积边界条件（这里读论文的时候读的迷迷糊糊的）。</li>
</ol>
<h4 id="3-分类实验"><a href="#3-分类实验" class="headerlink" title="3 分类实验"></a>3 分类实验</h4><p>&emsp;&emsp;ImageNet的classification最终结果由两个指标来进行评估，分别是top-1和top-5 error，前者是多类分类误差即不正确的分类图像占据的比例；后者是ILSVRC采用的主要评估标准，它是在前五个中都不是该图片类别的占比（即预测出来的前五个类别都不是该图片的类别所占总数的比例）。</p>
<h5 id="3-1-单尺度评估vs多尺度评估"><a href="#3-1-单尺度评估vs多尺度评估" class="headerlink" title="3.1 单尺度评估vs多尺度评估"></a>3.1 单尺度评估vs多尺度评估</h5><p>&emsp;&emsp;单尺度评估即设置测试数据集的图片大小唯一，即如果训练图片S固定，那么Q=S，如果训练图片S∈[S_min,S_max ]，那么Q=0.5(S_min+S_max)，最后的结果如下表所示：</p>
<p><img src="http://oyvr3xxmh.bkt.clouddn.com/17-12-18/40366083.jpg"><br>&emsp;&emsp;从上表中能得到的结论：</p>
<ul>
<li>AlexNet中提到的LRN层没有任何作用；</li>
<li>随着层数的增加，错误率也在不断地减小；</li>
<li>1x1卷积核引入后起到了一些作用（CA网络比B网络表现好），但拿C网络和D网络相比，3x3卷积核还是性能要比1x1的要好；</li>
<li>当层数达到19层后，网络的识别率已经达到了饱和；</li>
<li>一个具有小卷积核的深网络要完全胜过一个大卷积核的浅网络；</li>
<li>S以区间随机形式设置的方式结果要明显地好于用一个固定值设置。</li>
</ul>
<p>&emsp;&emsp;下面再来看多尺度评估的结果，多尺度评估是测试集图片的大小也不再是唯一了，而是取三个值最后将三个值的结果取平均进行预测。取法如下：如果S的大小固定，那么Q={S-32，S,S+32}，如果S的大小为一个区间内，那么Q={S_min，0.5(S_min+S_max),S_max }，下表为结果：</p>
<p><img src="http://oyvr3xxmh.bkt.clouddn.com/17-12-18/32921728.jpg"><br>&emsp;&emsp;该表的结果说明了多尺度的抖动效果要较优于单尺度。</p>
<h5 id="3-2-多网络融合"><a href="#3-2-多网络融合" class="headerlink" title="3.2 多网络融合"></a>3.2 多网络融合</h5><p>在进行实际的操作中，最终的分类结果是融合了好几个模型的结果进行平均化，结果如下：</p>
<p><img src="http://oyvr3xxmh.bkt.clouddn.com/17-12-18/30597725.jpg"></p>
<h4 id="4-总结"><a href="#4-总结" class="headerlink" title="4 总结"></a>4 总结</h4><p>VGG网络的重点如下：</p>
<ul>
<li>堆叠使用小卷积核（3x3卷积核）来代替大卷积核使网络变得更深更复杂；</li>
<li>网络越深对精度的提高越大；</li>
<li>但该网络的参数数量过于庞大搜索空间非常大。</li>
</ul>
<h4 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h4><p><a href="http://arxiv.org/abs/1409.1556" target="_blank" rel="external">VGG</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/12/16/AlexNet模型学习/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Li">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="http://oyvr3xxmh.bkt.clouddn.com/17-11-4/36375047.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="少年游">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/12/16/AlexNet模型学习/" itemprop="url">卷积神经网络模型学习（一）</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-12-16T23:38:08+08:00">
                2017-12-16
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/note/" itemprop="url" rel="index">
                    <span itemprop="name">note</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="1-LeNet5"><a href="#1-LeNet5" class="headerlink" title="1 LeNet5"></a>1 LeNet5</h3><p>&emsp;&emsp;LeNet5于1998年由Yang LeCun发布，从此深度学习这个领域开始为人所知，而在这个网络架构中很多东西在现如今的架构中也一直沿用着，比如卷积层（Convolutional Layer）加池化层（Polling Layer）加非线性激活层（Fully Connected Layer）这种CNN经典的组合也正是在这篇论文中提出的。</p>
<p>&emsp;&emsp;因为当时的技术有限，并没有如今的算力，无法采用GPU来进行运算，即使是CPU的运算也相当缓慢。相较于今天各种网络，这个五层网络是一个非常小的网络，只有大约60,000参数需要训练，而在现在你所看到的一些常见网络中，参数无不是从千万到亿级别的，如下为LeNet5架构：</p>
<p><img src="http://oyvr3xxmh.bkt.clouddn.com/17-12-15/91909246.jpg"><br>&emsp;&emsp;当时LeCun是针对黑白的手写数字图片进行识别，如下图所示：</p>
<p><img src="http://oyvr3xxmh.bkt.clouddn.com/17-12-16/30031856.jpg"><br>&emsp;&emsp;在这里我们可以看到输入的图片为一个32x32像素的黑白图片，所以chanel为1，然后经过一个5x5的convolutional filter进行卷积之后再经过avg pooling层，重复两次最终跟上两个个全连接层进行输出，在当时并没有采用softmax function进行输出，当时所采用的输出方法现已经淘汰，这里我们一般都会采用softmax function进行输出。</p>
<p>&emsp;&emsp;LeNet5所做的工作是一个开创性的工作，其提出了CNN的三大特性：1.局部感知（卷积核）；2.下采样（池化）；3.权值共享，总得来说正是LeNet5架构把人们带入了深度学习的领域。</p>
<h3 id="2-AlexNet"><a href="#2-AlexNet" class="headerlink" title="2 AlexNet"></a>2 AlexNet</h3><p>&emsp;&emsp;在1998-2012这十多年间，神经网络的发展异常的缓慢，而2012年由Alex Krizhevsky发表的AlexNet以绝对的优势赢得了当年的ImageNet竞赛的第一，技惊四座，也正是从此深度学习和神经网络又大范围地回到人们的视野。</p>
<p><img src="http://oyvr3xxmh.bkt.clouddn.com/17-12-16/78152235.jpg"><br>&emsp;&emsp;上图为ImageNet classification每届冠军队伍最后的错误率，我们可以看到在2012年神经网络及AlexNet的出现将错误率硬生生地下降了几乎10%，这在之前看来提升速度是非常夸张的，接着来看AlexNet的7层架构图：</p>
<p><img src="http://oyvr3xxmh.bkt.clouddn.com/17-12-15/82690531.jpg"><br>&emsp;&emsp;没错，这个架构和LeNet5非常地相似，两者之间的主要区别点在于首先AlexNet将层数提升到了7，其次将LeNet5中的Avg Pooling层均换成了Max Pooling层，再有在LeNet5那个年代激活函数用的均是sigmoid function或tanh function，而AlexNet则采用了如今依然非常有用的ReLU function，还有一些诸如过拟合的处理、多GPU等下面将选择部分讲述。</p>
<p>&emsp;&emsp;该论文数据集选用的为ILSVRC-2010，这个数据集包含了1000中类别，每个类别大致有1000张左右的图片，120万的training dataset，50000的validation dataset和150000的testing dataset。</p>
<h4 id="2-1-ReLU-Rectified-Linear-Units-激活函数"><a href="#2-1-ReLU-Rectified-Linear-Units-激活函数" class="headerlink" title="2.1 ReLU(Rectified Linear Units)激活函数"></a>2.1 ReLU(Rectified Linear Units)激活函数</h4><p>&emsp;&emsp;传统的神经网络大多采用f(x)=tanh⁡(x)或者f(x)=〖(1+e^(-x))〗^(-1)作为激活函数，在进行梯度下降的训练过程中，这些饱和非线性函数比非饱和非线性函数f(x)=max⁡(0,x)训练的要慢得多。</p>
<p><img src="http://oyvr3xxmh.bkt.clouddn.com/17-12-15/35591579.jpg"><br>&emsp;&emsp;如上图所示，实线代表ReLU激励函数，虚线代表tanh激励函数，在同样的神经网络下，ReLU只需要6次迭代即可达到25%的训练错误率，而tanh则需要35次以上的迭代次数，这里就可以看出ReLU在对网络越大，参数越多的情况下训练速度的提升是非常明显的。</p>
<h4 id="2-2-架构"><a href="#2-2-架构" class="headerlink" title="2.2 架构"></a>2.2 架构</h4><p>&emsp;&emsp;从AlexNet的架构图以及论文的描述中我们可以得到AlexNet的具体细节如下图所示：</p>
<p><img src="http://oyvr3xxmh.bkt.clouddn.com/17-12-15/52657695.jpg"><br>&emsp;&emsp;可以看到AlexNet共有5层卷积层，其中前两个卷积层后均跟着一个最大池化层和正则层，之后连续跟了三个卷积层以及一个最大池化层，最后是三层全连接层。注意Response Normalization Layer这个是用来做归一化处理的，而且在所有的卷积层和全连接层都用到了ReLU函数，而且从图4中也能看出来上下两个分别是在两个GPU上运行。其中每一层的神经元的个数分别为253440-186624-64896-64896-43264-4096-4096-1000，从这里我们能够看到绝大多数的神经元均集中在了卷积层，因为卷积层要对数据进行不断的升维。</p>
<h4 id="2-3-减少过拟合"><a href="#2-3-减少过拟合" class="headerlink" title="2.3 减少过拟合"></a>2.3 减少过拟合</h4><p>&emsp;&emsp;在神经网络的训练过程中，一直存在着两种问题：欠拟合和过拟合。AlexNet有大约6千万的参数要训练，同样存在着过拟合的问题，而针对过拟合AlexNet采取了两种方法来对抗。</p>
<h5 id="2-3-1-Data-Augmentation"><a href="#2-3-1-Data-Augmentation" class="headerlink" title="2.3.1 Data Augmentation"></a>2.3.1 Data Augmentation</h5><p>&emsp;&emsp;Data Augmentation的意思是数据增强，这是一个针对过拟合很常用的方法，既然模型过拟合，那么加大数据的输入量能在很大程度上减缓过拟合。而AlexNet在数据增强这方面的做法便是对输入的256x256的图片随意截取其224x224像素的部分，标签仍然是原来的标签，这样直接将训练数据集的大小增加了2048倍。而在针对测试集进行预测的时候，首先取出图片四个角落和中心被裁剪过的224x224图片，再加其余任意裁剪后的224x224五张图，共十张图进行预测，最后将10个结果取平均来得到最终的结果。另一个增强数据量的方法是改变每张图片的RGB值来得到更多的图片（这里采用了PCA），这样做最后的结果也表明了图像对比度和颜色的变化对图像本身的识别是不会产生影响的。</p>
<h5 id="2-3-2-Dropout"><a href="#2-3-2-Dropout" class="headerlink" title="2.3.2 Dropout"></a>2.3.2 Dropout</h5><p>&emsp;&emsp;Dropout是近几年非常流行的一个处理神经网络过拟合方法，在AlexNet中第二种处理过拟合便采用了dropout。Dropout的原理便是，设置一个dropout值，这样神经网络每层将有一定比例的神经元在当前epoch失效。</p>
<p><img src="http://oyvr3xxmh.bkt.clouddn.com/17-12-16/45381178.jpg"><br>&emsp;&emsp;如上图所示，设置dropout值为0.5，那么在每次的epoch中，每层的神经元将会有50%在神经网络的前向传播和后向传播中不在做出贡献，当然也可以针对每一层各自设置一个dropout值，实验表明该方法能有效地去对抗神经网络的过拟合。Dropout的作用减少了神经元之间的相互依赖，因为每一个epoch都无法保证上一趟epoch所依赖的神经元是否会在这次消失，这样使得每个神经云尽可能地学会更多特征。而也正是dropout的使用使得AlexNet极大地减轻了过拟合带来的损失，并使训练的次数翻倍。还有一点需要注意的是，dropout只需要用在训练的过程，而在针对测试数据集时是不能使用dropout的，那样做只会对你的预测增加噪声。还有一点需要注意的是，在对每一层使用完dropout后所得到的值，比如第三层共有30个神经元，设置dropout的值为0.8，这样有6个神经元在一趟epoch中被消除，而得到的结果需要除以dropout的值。即在这一层得到的值还需要都除以0.8后再传向下一层。</p>
<h4 id="2-4-训练细节"><a href="#2-4-训练细节" class="headerlink" title="2.4 训练细节"></a>2.4 训练细节</h4><p>&emsp;&emsp;AlexNet模型采用了随机梯度下降（SGD），设置mini batch的大小为128，momentum参数为0.9（momentum的作用是为了加速随机梯度下降在某一个方向上的搜索，并减少模型的震荡导致无法收敛），权值衰减设为0.0005（目的主要是为了防止过拟合），权值更新的公式如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">v_(i+1)≔0.9∙v_i-0.0005∙ϵ∙ω_i-ϵ∙⟨∂L/∂ω│ω_i ⟩_(D_i )</div><div class="line"></div><div class="line">ω_(i+1)≔ω_i+v_(i+1)</div></pre></td></tr></table></figure></p>
<p>&emsp;&emsp;其中i是迭代参数，v为momentum参数，ϵ为学习速率，⟨∂L/∂ω│ω<em>i ⟩</em>(D_i )是目标函数对ω，在ω_i上的第i批微分D_i的平均。AlexNet学习速率的设置是手动调节的，起始的学习速率为0.01，当validation数据集的错误率不再变化的时候将学习速率调小十倍后继续训练。</p>
<h4 id="2-5-总结"><a href="#2-5-总结" class="headerlink" title="2.5 总结"></a>2.5 总结</h4><p>&emsp;&emsp;AlexNet模型的重点如下:</p>
<ol>
<li>使用了ReLU作为非线性激活函数;</li>
<li>使用了两种数据扩增的方式（裁剪和改变RGB的强度）;</li>
<li>将LeNet5的Avg Pooling改成了Max Pooling;</li>
<li>使用dropout来避免过拟合增大了迭代次数;</li>
<li>使用双GPU进行训练。</li>
</ol>
<h4 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h4><p><a href="http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf" target="_blank" rel="external">LeNet5</a><br><a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" target="_blank" rel="external">AlexNet</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  


          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="http://oyvr3xxmh.bkt.clouddn.com/17-11-4/36375047.jpg"
                alt="Li" />
            
              <p class="site-author-name" itemprop="name">Li</p>
              <p class="site-description motion-element" itemprop="description">无病呻吟...</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">1</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">2</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          <div class="links-of-author motion-element">
            
          </div>

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Li</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.3</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.3"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script>



  


  




	





  





  









<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="//unpkg.com/valine/dist/Valine.min.js"></script>



  





  

  

  

  
  

  

  

  

</body>
</html>
